{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "086b8faf",
   "metadata": {},
   "source": [
    "# Jupyter notebook for Privacy in Data Storage\n",
    "\n",
    "In this notebook we explore privacy and ethics in Data Storage. We will look at concepts like k-anonymity, l-diversity, t-closeness etc. This notebook includes exercises in python and discussions. \n",
    "\n",
    "It should be done in **groups**, especially the discussions, to get the full learning effect.\n",
    "\n",
    "\n",
    "### The goal of this notebook\n",
    "\n",
    "1. Be able to anonymize data and analyse anonymous data for re-identification\n",
    "\n",
    "2. Learn the concepts of k-anonymity, l-diversity, t-closeness and function creep as examples of privacy related topics\n",
    "\n",
    "3. Identify assumptions and biases in some datasets. For example in categorising data, in particular for a categorisation that is up for discussion (e.g. gender = [male, female])\n",
    "\n",
    "4. The students should be able to analyse the potential dangers (The impact on (vulnerable) users, society and source of the data) of working with unrestricted and controversial data like health diseases, crime or similar topics\n",
    "\n",
    "### Prior knowledge needed\n",
    "\n",
    "- The user should be familiar with python and jupyter notebooks\n",
    "\n",
    "- The user should be familiar with the pandas library in python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a87054c1",
   "metadata": {},
   "source": [
    "## Warmup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e8fe81b",
   "metadata": {},
   "source": [
    "Before we go through examples and exercies you should take a moment to reflect over the following questions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "253b9bc5",
   "metadata": {},
   "source": [
    "**1. What is the meaning of \"sensible-data\" according to you? Could you name some?**"
   ]
  },
  {
   "cell_type": "raw",
   "id": "53653419",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ad428961",
   "metadata": {},
   "source": [
    "**2. What is the purpose of anonymization? Is it even important?**"
   ]
  },
  {
   "cell_type": "raw",
   "id": "87fdc4f2",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "eb62db0b",
   "metadata": {},
   "source": [
    "**3. What are the main issues linked to re-identification of a person?**"
   ]
  },
  {
   "cell_type": "raw",
   "id": "9c3c5d32",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1376c669",
   "metadata": {},
   "source": [
    "# Anonymization of data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63dca5a5",
   "metadata": {},
   "source": [
    "In the following part we will go through an example of where anonymization could be useful and k-anonymity could help achieve anonymization."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c112920",
   "metadata": {},
   "source": [
    "Health information is widely acknowledged to be sensitive personal information. Information of this type may contain facts about an individual that can be used by insurance companies, future employers or others against the benefit of the person involved. For this reason, in many countries and jurisdictions, gathering, storing and publishing such data by third parties is limited by laws and regulations. In general, the gist of this type of legislation is twofold. For a third party to be allowed to process health data, either:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e339515",
   "metadata": {},
   "source": [
    "* the person the information is about has given permission for usage\n",
    "* the data is changed in such a way that it is not possible to determine the identity of the individual\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7ccd58f",
   "metadata": {},
   "source": [
    "Although health data is sensitive in the sense described above, large health datasets can offer a wealth of information to scientists and researchers, for example in determining the effects of specific medication or finding correlations between lifestyle and disease. However, datasets with this type of information may not be used without satisfying either of the conditions mentioned."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d406852",
   "metadata": {},
   "source": [
    "Especially for large existing datasets, it can be very difficult, if not completely infeasible, to obtain permission from each individual in the dataset. In order to use this data without jeopardizing an individuals privacy and stay within legal boundaries, the data needs to be changed in such a way that it is impossible to determine the identity of individual the information is about. This process is commonly referred to as **anonymization**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "203fb240",
   "metadata": {},
   "source": [
    "A common solution for anonymization is simply removing all values from the dataset that identify a person directly, e.g. remove a person's name and SSI. Sometimes a variant known as pseudonimization is used, where this information is not removed, but replaced by a specific ID number. This ID number can only be traced back to the person involved through a Trusted Third Party (TTP)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91098d42",
   "metadata": {},
   "source": [
    "Depending on context, these methods have advantages and disadvantages. One important observation however, is that very often the second condition is not adequately satisfied: it is still possible to infer the identity of the person involved from the given data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8055ba71",
   "metadata": {},
   "source": [
    "Consider the following (hypothetical) example of an anonymized dataset published by Dr. Bob for medical research."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17f9d605",
   "metadata": {},
   "source": [
    "![jupyter](example.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e50ab660",
   "metadata": {},
   "source": [
    "#### Discussion 1\n",
    "\n",
    "At first glance, no identifiable information has been leaked in this dataset. But take a moment and discuss with your group. Could there be any potential dangers for anonymity?"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c8a05973",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c30bb6d9",
   "metadata": {},
   "source": [
    "Imagine you walk by Dr. Bob's office and see a person with the following characteristics:\n",
    "\n",
    "* She is a woman\n",
    "* She is quite young (at least younger than 20 by estimation)\n",
    "* She has an occupation as chef or baker (or something that requires similar attire, as she wears a chef's hat)\n",
    "\n",
    "While any of these characteristics by themselves would match multiple records in the dataset, there's only one record that satisfies all three. Therefore we can learn the medical condition of this person and Dr. Bob has revealed personal information about one of his patients.\n",
    "\n",
    "Of course, in this example re-identifying a person is quite easy, because the dataset is relatively small. In a larger dataset, one could argue, more young, female chefs might be included, making it more difficult or even impossible to determine the exact record in the dataset depicting the person from the photo.\n",
    "\n",
    "This argument makes sense; a real-world dataset would probably contain many more records than the example. However, such a real-world dataset usually also contains many more columns (i.e. more data per record). It's not difficult to see that more data increases the risk of re-identification again. Furthermore, many people may be indistinguishable (or equivalent) within the dataset, but some records will still have a unique combination of values. As an example, someone with a very uncommon profession and being above 100 years old is still easily re-identified in most large datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f289da5",
   "metadata": {},
   "source": [
    "#### Discussion 2\n",
    "\n",
    "How can we mitigate this type of risk?"
   ]
  },
  {
   "cell_type": "raw",
   "id": "1b13138b",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ae1bb3bf",
   "metadata": {},
   "source": [
    "We could leave out many of the columns, but this would destroy most of the analytical value in the data, which defeats the purpose of releasing the data in the first place. A better solution would leave out as much data as needed to prevent re-identification, but not more. Such a solution would allow us to retain analytical value as much as possible, while respecting privacy for subjects involved. The trade-off we seek to optimize can be depicted a follows:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8be2cfa",
   "metadata": {},
   "source": [
    "![jupyter](example2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74ed3b83",
   "metadata": {},
   "source": [
    "The solution for the problem described above: make sure that every record has at least one equivalent record, i.e. a record that contains the same values on all properties that are publicly known or easy to determine."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f5caf54",
   "metadata": {},
   "source": [
    "## k-anonymity\n",
    "\n",
    "The concept of k-anonymity is used to express the level of privacy in a dataset. In a dataset that was de-identified following a k-anonymity algorithm, all records are equivalent to one or more other records, creating a group of equivalent records, or equivalence class. The size of the smallest of these groups in a dataset is the value of k."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1cf4fca",
   "metadata": {},
   "source": [
    "#### Discussion 3\n",
    "\n",
    "What would be needed to make the above dataset k-2-anonymous?"
   ]
  },
  {
   "cell_type": "raw",
   "id": "3aaa8edc",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a0c6bc87",
   "metadata": {},
   "source": [
    "See for example an adapted version of the table above:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c59a66e2",
   "metadata": {},
   "source": [
    "![jupyter](example3.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2091b91a",
   "metadata": {},
   "source": [
    "When we ignore the (presumably not publicly known) _Medical condition_ column, every record in the table above has at least one duplicate. The smallest set of equivalent records (i.e. the smallest equivalence class) in this table has size two (e.g. the set Male/50+/Yes). Thus this table can be considered 2-anonymous. Note that real-world values for _k_ are usually a lot larger."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "014c177b",
   "metadata": {},
   "source": [
    "## How to achieve k-anonymity\n",
    "\n",
    "Looking at the table above, we can observe the changes that made this dataset reach the 2-anonymity level:\n",
    "\n",
    "* One record was completely suppressed\n",
    "* The age value for each record was classified into one of two categories: 50- or 50+\n",
    "* The occupation value for each record was generalized into Yes or No\n",
    "\n",
    "These observations show two common techniques regularly used in combination to achieve a certain level of anonymity:\n",
    "\n",
    "* Suppression: leaving out records that have a very unique combination of attribute values\n",
    "* Generalization: making values more generic, so that more records share the same value\n",
    "\n",
    "In applying these techniques, decisions have to be made about which records to suppress and to what extent the columns should be generalized. These decisions can depend on the purpose the dataset is released for: age may be a relevant variable in some scientific studies, but less so in others. Very often however, datasets are released for a general purpose or the purpose may be difficult to obtain. In these cases, algorithms may be used that try to reach k-anonymity with the least amount of suppression and generalization possible. These algorithms typically involve trying a lot of combinations of generalization levels and suppression criteria, before an optimal solution is chosen."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "665ab619",
   "metadata": {},
   "source": [
    "## Implementing k-anonymity\n",
    "\n",
    "In this notebook, we'll explore data anonymization, in particular \"k-anonymity\" [1]. We will implement a simple algorithm [2] to produce a k-anonymous dataset.\n",
    "\n",
    "For more reading on the topic, please see: \n",
    "\n",
    "- [k-Anonymity: A Model For Protecting Privacy. Latanya Sweeney](https://epic.org/privacy/reidentification/Sweeney_Article.pdf)\n",
    "- [Mondrian - Multidimensional k-Anonymity](https://www.utdallas.edu/~muratk/courses/privacy08f_files/MultiDim.pdf)\n",
    "\n",
    "Turning a dataset into a k-anonymous (and possibly l-diverse or t-close) dataset is a complex problem, and finding the optimal partition into k-anonymous groups is an NP-hard problem. Fortunately, several practical algorithms exists that often produce \"good enough\" results by employing greedy search techniques.\n",
    "\n",
    "In this tutorial we will explore the so-called \"Mondrian\" algorithm (see link above), which uses a greedy search algorithm to parition the original data into smaller and smaller groups (if we plot the resulting partition boundaries in 2D they resemble the pictures by Piet Mondrian, hence the name).\n",
    "\n",
    "The algorithm assumes that we have converted all attributes into numerical or categorical values and that we're able to measure the \"span\" of a given data attribute $X_i$ (we'll explain that in more detail later)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1390e0b0",
   "metadata": {},
   "source": [
    "### Partitioning Algorithm\n",
    "\n",
    "The algorithm proceeds then as follows to partition the data into k-anonymous gorups:\n",
    "\n",
    "1. Initialize the finished set of partitions to an empty set $P_{finished} = \\{\\}$.\n",
    "2. Initialize the working set of paritions to a set containing a partition with the entire dataset $P_{working} = \\{\\{1, 2,\\dots ,N\\}\\}$.\n",
    "4. While there are partitions in the working set, pop one partition from it and\n",
    "  * Calculate the relative spans of all columns in the partition.\n",
    "  * Sort the resulting columns by their span (in descending order) and iterate over them. For each column,\n",
    "      * Try to split the partition along that column using the median of the column values as the split point.\n",
    "      * Check if the resulting partitions are valid according to our k-anonymity (and possibly additional) criteria.\n",
    "      * If yes, add the two new partitions to the working set and break out of the loop.\n",
    "  * If no column produced a valid split, add the original partition to the set of finished partitions.\n",
    "5. Return the finished set of partitions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e07d15b",
   "metadata": {},
   "source": [
    "### Data Aggregation\n",
    "\n",
    "After obtaining the partitions we still need to aggregate the values of the quasi identifiers and the sensitive attributes in each k-anonymous group. For this, we can e.g. replace numerical attributes with their range (e.g. \"age: 24-28\") and categorical attributes with their union (e.g. \"employment-group: [self-employed, employee, worker]\"), though other aggregations are possible. Methods like [Anatomy](http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.156.9150&rep=rep1&type=pdf) even preserve the micro-data in each group, which increases re-identification risk though.\n",
    "\n",
    "We can then use the anonymized data for privacy-preserving machine learning, e.g. using scikit-learn or something similar."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10f9d34d",
   "metadata": {},
   "source": [
    "#### Discussion 4\n",
    "\n",
    "What should you think about after you have implemented k-anonymity on a dataset?"
   ]
  },
  {
   "cell_type": "raw",
   "id": "3bd1dbe7",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9c6bd5b3",
   "metadata": {},
   "source": [
    "## Programming k-anonymity\n",
    "\n",
    "Let's get started with the programming!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bb22011b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we use Pandas to work with the data as it makes working with tables of data super easy\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "906959d7",
   "metadata": {},
   "source": [
    "We start by importing some data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c31124ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is a list of the column names in our dataset (as the file doesn't contain any headers)\n",
    "names = (\n",
    "    'age',\n",
    "    'workclass', #Private, Self-emp-not-inc, Self-emp-inc, Federal-gov, Local-gov, State-gov, Without-pay, Never-worked.\n",
    "    'fnlwgt', # \"weight\" of that person in the dataset (i.e. how many people does that person represent) -> https://www.kansascityfed.org/research/datamuseum/cps/coreinfo/keyconcepts/weights\n",
    "    'education',\n",
    "    'education-num',\n",
    "    'marital-status',\n",
    "    'occupation',\n",
    "    'relationship',\n",
    "    'race',\n",
    "    'sex',\n",
    "    'capital-gain',\n",
    "    'capital-loss',\n",
    "    'hours-per-week',\n",
    "    'native-country',\n",
    "    'income',\n",
    ")\n",
    "\n",
    "# some fields are categorical and will require special treatment\n",
    "categorical = set((\n",
    "    'workclass',\n",
    "    'education',\n",
    "    'marital-status',\n",
    "    'occupation',\n",
    "    'relationship',\n",
    "    'sex',\n",
    "    'native-country',\n",
    "    'race',\n",
    "    'income',\n",
    "))\n",
    "\n",
    "df = pd.read_csv(\"Data/adult.all.txt\", sep=\", \", header=None, names=names, index_col=False, engine='python');# We load the data using Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bdb56abe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>77516</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>2174</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50k</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>83311</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50k</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>215646</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50k</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53</td>\n",
       "      <td>Private</td>\n",
       "      <td>234721</td>\n",
       "      <td>11th</td>\n",
       "      <td>7</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50k</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>Private</td>\n",
       "      <td>338409</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Wife</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>Cuba</td>\n",
       "      <td>&lt;=50k</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age         workclass  fnlwgt  education  education-num  \\\n",
       "0   39         State-gov   77516  Bachelors             13   \n",
       "1   50  Self-emp-not-inc   83311  Bachelors             13   \n",
       "2   38           Private  215646    HS-grad              9   \n",
       "3   53           Private  234721       11th              7   \n",
       "4   28           Private  338409  Bachelors             13   \n",
       "\n",
       "       marital-status         occupation   relationship   race     sex  \\\n",
       "0       Never-married       Adm-clerical  Not-in-family  White    Male   \n",
       "1  Married-civ-spouse    Exec-managerial        Husband  White    Male   \n",
       "2            Divorced  Handlers-cleaners  Not-in-family  White    Male   \n",
       "3  Married-civ-spouse  Handlers-cleaners        Husband  Black    Male   \n",
       "4  Married-civ-spouse     Prof-specialty           Wife  Black  Female   \n",
       "\n",
       "   capital-gain  capital-loss  hours-per-week native-country income  \n",
       "0          2174             0              40  United-States  <=50k  \n",
       "1             0             0              13  United-States  <=50k  \n",
       "2             0             0              40  United-States  <=50k  \n",
       "3             0             0              40  United-States  <=50k  \n",
       "4             0             0              40           Cuba  <=50k  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Take a look at the dataset\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29e2720d",
   "metadata": {},
   "source": [
    "#### Discussion 5\n",
    "\n",
    "Are there any potensial biases you should think about when working with this dataset?"
   ]
  },
  {
   "cell_type": "raw",
   "id": "73ee004f",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c5982ec0",
   "metadata": {},
   "source": [
    "**Implement a function that returns the spans (max-min for numerical columns, number of different values for categorical columns) of all columns for a partition of a dataframe.** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "055b2508",
   "metadata": {},
   "outputs": [],
   "source": [
    "for name in categorical:\n",
    "    df[name] = df[name].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "070a445d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_spans(df, partition):\n",
    "    \"\"\"\n",
    "    :param        df: the dataframe for which to calculate the spans\n",
    "    :param partition: the partition for which to calculate the spans\n",
    "    :        returns: The spans of all columns in the partition\n",
    "    \"\"\"\n",
    "    spans = {}\n",
    "    for column in df.columns:\n",
    "        if column in categorical:\n",
    "            span = len(df[column][partition].unique())\n",
    "        else:\n",
    "            span = df[column][partition].max()-df[column][partition].min()\n",
    "        spans[column] = span\n",
    "    return spans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bd33addb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'age': 73,\n",
       " 'workclass': 9,\n",
       " 'fnlwgt': 1478115,\n",
       " 'education': 16,\n",
       " 'education-num': 15,\n",
       " 'marital-status': 7,\n",
       " 'occupation': 15,\n",
       " 'relationship': 6,\n",
       " 'race': 5,\n",
       " 'sex': 2,\n",
       " 'capital-gain': 99999,\n",
       " 'capital-loss': 4356,\n",
       " 'hours-per-week': 98,\n",
       " 'native-country': 42,\n",
       " 'income': 2}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_spans = get_spans(df, df.index)\n",
    "full_spans"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b545d1b9",
   "metadata": {},
   "source": [
    "The answer should be like this:\n",
    "\n",
    "```\n",
    "{'age': 73,\n",
    " 'workclass': 9,\n",
    " 'fnlwgt': 1478115,\n",
    " 'education': 16,\n",
    " 'education-num': 15,\n",
    " 'marital-status': 7,\n",
    " 'occupation': 15,\n",
    " 'relationship': 6,\n",
    " 'race': 5,\n",
    " 'sex': 2,\n",
    " 'capital-gain': 99999,\n",
    " 'capital-loss': 4356,\n",
    " 'hours-per-week': 98,\n",
    " 'native-country': 42,\n",
    " 'income': 2}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbf98a99",
   "metadata": {},
   "source": [
    "**Implement a `split` function that split the given partition such that all rows with values of the column `column` below the median are in one partition and all rows with values above or equal to the median are in the other.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "11fabeb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split(df, partition, column):\n",
    "    \"\"\"\n",
    "    :param        df: The dataframe to split\n",
    "    :param partition: The partition to split\n",
    "    :param    column: The column along which to split\n",
    "    :        returns: A tuple containing a split of the original partition\n",
    "    \"\"\"\n",
    "    dfp = df[column][partition]\n",
    "    if column in categorical:\n",
    "        values = dfp.unique()\n",
    "        lv = set(values[:len(values)//2])\n",
    "        rv = set(values[len(values)//2:])\n",
    "        return dfp.index[dfp.isin(lv)], dfp.index[dfp.isin(rv)]\n",
    "    else:        \n",
    "        median = dfp.median()\n",
    "        dfl = dfp.index[dfp < median]\n",
    "        dfr = dfp.index[dfp >= median]\n",
    "        return (dfl, dfr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a2b70108",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Int64Index([4, 5, 8, 10, 11, 12, 13, 15, 16, 17], dtype='int64'),\n",
       " Int64Index([0, 1, 2, 3, 6, 7, 9, 14, 18, 19], dtype='int64'))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We test the split function on a subset of the dataset\n",
    "partitions = split(df, df[:20].index, 'age')\n",
    "partitions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7e26cd1",
   "metadata": {},
   "source": [
    "The output should be like this:\n",
    "```\n",
    "(Int64Index([4, 5, 8, 10, 11, 12, 13, 15, 16, 17], dtype='int64'),\n",
    " Int64Index([0, 1, 2, 3, 6, 7, 9, 14, 18, 19], dtype='int64'))\n",
    "```\n",
    "It displays which of our rows belong to each partition. We can see that this particular partitioning was really even. \n",
    "\n",
    "**The next helper function we need is just for detecting if a partition is big enough to satisfy our `k`.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b73d5104",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_k_anonymous(df, partition, sensitive_column, k=3):\n",
    "    \"\"\"\n",
    "    :param               df: The dataframe on which to check the partition.\n",
    "    :param        partition: The partition of the dataframe to check.\n",
    "    :param sensitive_column: The name of the sensitive column\n",
    "    :param                k: The desired k\n",
    "    :returns               : True if the partition is valid according to our k-anonymity criteria, False otherwise.\n",
    "    \"\"\"\n",
    "    if len(partition) < k:\n",
    "        return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82522c32",
   "metadata": {},
   "source": [
    "Now that we have all helper functions in place, we can implement the partition algorithm discussed above:\n",
    "\n",
    "**Implement the partitioning algorithm descibed in the Partitioning Algorithm section, using a k-anonymous criterion for the partitions you create.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d6772210",
   "metadata": {},
   "outputs": [],
   "source": [
    "def partition_dataset(df, feature_columns, sensitive_column, is_valid):\n",
    "    \"\"\"\n",
    "    :param               df: The dataframe to be partitioned.\n",
    "    :param  feature_columns: A list of column names along which to partition the dataset.\n",
    "    :param sensitive_column: The name of the sensitive column (to be passed on to the `is_valid` function)\n",
    "    :param         is_valid: A function that takes a dataframe and a partition and returns True if the partition is valid.\n",
    "    :returns               : A list of valid partitions that cover the entire dataframe.\n",
    "    \"\"\"\n",
    "    finished_partitions = []\n",
    "    partitions = [df.index]\n",
    "    while partitions:\n",
    "        partition = partitions.pop(0)\n",
    "        spans = get_spans(df[feature_columns], partition)\n",
    "        # Get the columns with spans in descending order\n",
    "        for column, span in sorted(spans.items(), key=lambda x:-x[1]):\n",
    "            # Split the partitioned columns and check if they are of valid length\n",
    "            lp, rp = split(df, partition, column)\n",
    "            if not is_valid(df, lp, sensitive_column) or not is_valid(df, rp, sensitive_column):\n",
    "                continue\n",
    "            #if they are of valid length, add them to partitions for next iteration to check if they can be further divided\n",
    "            partitions.extend((lp, rp))\n",
    "            break\n",
    "        else:\n",
    "            finished_partitions.append(partition)\n",
    "    return finished_partitions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fb68e13",
   "metadata": {},
   "source": [
    "Now let's try this on our dataset! To keep things simple, we will at first select only two columns from the dataset that we apply the partitioning to. This makes it easier to check/visualize the result and speed up the execution (the naive algorithm can take several minutes when running on the entire dataset) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eabe51a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we apply our partitioning method to two columns of our dataset, using \"income\" as the sensitive attribute\n",
    "feature_columns = ['age', 'education-num']\n",
    "sensitive_column = 'income'\n",
    "finished_partitions = partition_dataset(df, feature_columns, sensitive_column, is_k_anonymous)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9dd4e9b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "477"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we get the number of partitions that were created\n",
    "len(finished_partitions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44d3ca23",
   "metadata": {},
   "source": [
    "The output of this should be: `477`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3096a4b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "age              21\n",
      "education-num    10\n",
      "Name: 36, dtype: int64\n",
      "age              21\n",
      "education-num    10\n",
      "Name: 120, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# We can check that two rows should belong in the same partition\n",
    "partition = finished_partitions[0]\n",
    "print(df[feature_columns].iloc[partition[0]])\n",
    "print(df[feature_columns].iloc[partition[1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea3884a6",
   "metadata": {},
   "source": [
    "You should get:\n",
    "```\n",
    "age              21\n",
    "education-num    10\n",
    "Name: 36, dtype: int64\n",
    "age              21\n",
    "education-num    10\n",
    "Name: 120, dtype: int64\n",
    "```\n",
    "We can see that they should both belong in the same partition."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6ed478c",
   "metadata": {},
   "source": [
    "# Generating an k-Anonymous Dataset\n",
    "\n",
    "Of course, to use the data we want to produce a new dataset that contains one row for each partition and value of the sensitive attribute. To do this, we need to aggregate the columns in each partition.  Let's do this!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0da4bd9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining ways to aggregate the values for the final dataset\n",
    "# Be careful about these as they could reveal all aggregated data the way they are currently implemented\n",
    "def agg_categorical_column(series):\n",
    "    return [','.join(set(series))]\n",
    "\n",
    "def agg_numerical_column(series):\n",
    "    return [series.mean()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0caae901",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_anonymized_dataset(df, partitions, feature_columns, sensitive_column):\n",
    "    aggregations = {}\n",
    "    for column in feature_columns:\n",
    "        # Define the row values for the final dataset by aggregation\n",
    "        if column in categorical:\n",
    "            aggregations[column] = agg_categorical_column\n",
    "        else:\n",
    "            aggregations[column] = agg_numerical_column\n",
    "    # Here we store the generated rows\n",
    "    rows = []\n",
    "    for partition in partitions:\n",
    "        grouped_columns = df.loc[partition].agg(aggregations, squeeze=False)\n",
    "        sensitive_counts = df.loc[partition].groupby(sensitive_column).agg({sensitive_column : 'count'})\n",
    "        values = {}\n",
    "        for name,val in grouped_columns.items():\n",
    "            values[name] = val[0]\n",
    "        for sensitive_value, count in sensitive_counts[sensitive_column].items():\n",
    "            # Drop empty rows\n",
    "            if count == 0:\n",
    "                continue\n",
    "            values.update({\n",
    "                sensitive_column : sensitive_value,\n",
    "                'count' : count,\n",
    "            })\n",
    "            rows.append(values.copy())\n",
    "    return pd.DataFrame(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e5a2e642",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the k-anonymized dataset\n",
    "dfn = build_anonymized_dataset(df, finished_partitions, feature_columns, sensitive_column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "df9cb2a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>education-num</th>\n",
       "      <th>income</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>500</th>\n",
       "      <td>17.0</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>&lt;=50k</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>17.0</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>&lt;=50k</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213</th>\n",
       "      <td>17.0</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>&lt;=50k</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17.0</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>&lt;=50k</td>\n",
       "      <td>267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>17.0</td>\n",
       "      <td>8.172840</td>\n",
       "      <td>&lt;=50k</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>734</th>\n",
       "      <td>90.0</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>&gt;50k</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>762</th>\n",
       "      <td>90.0</td>\n",
       "      <td>10.545455</td>\n",
       "      <td>&lt;=50k</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>763</th>\n",
       "      <td>90.0</td>\n",
       "      <td>10.545455</td>\n",
       "      <td>&gt;50k</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>764</th>\n",
       "      <td>90.0</td>\n",
       "      <td>13.647059</td>\n",
       "      <td>&lt;=50k</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>765</th>\n",
       "      <td>90.0</td>\n",
       "      <td>13.647059</td>\n",
       "      <td>&gt;50k</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>791 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      age  education-num income  count\n",
       "500  17.0       3.000000  <=50k      3\n",
       "501  17.0       4.000000  <=50k      5\n",
       "213  17.0       5.000000  <=50k     36\n",
       "17   17.0       7.000000  <=50k    267\n",
       "19   17.0       8.172840  <=50k     81\n",
       "..    ...            ...    ...    ...\n",
       "734  90.0       9.000000   >50k      4\n",
       "762  90.0      10.545455  <=50k      9\n",
       "763  90.0      10.545455   >50k      2\n",
       "764  90.0      13.647059  <=50k     10\n",
       "765  90.0      13.647059   >50k      7\n",
       "\n",
       "[791 rows x 4 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we sort the resulting dataframe using the feature columns and the sensitive attribute\n",
    "dfn.sort_values(feature_columns+[sensitive_column])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61da000f",
   "metadata": {},
   "source": [
    "The output should be like this:\n",
    "\n",
    "|     | age |\teducation-num |\tincome   |\tcount |\n",
    "|-----|-----|-----------------|----------|--------|\n",
    "| 469 |\t17.0|      \t3.000000  |\t<=50k    |\t3     |\n",
    "| 615 |\t17.0|      \t4.000000  |\t<=50k    |\t5     |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53c7e33b",
   "metadata": {},
   "source": [
    "## Finishing questions\n",
    "\n",
    "We have now implemented k-anonymity and checked that it works.\n",
    "\n",
    "Here are some finishing questions to help you reflect over what you ahve learned and keep in touch with the goals of the notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dd9c666",
   "metadata": {},
   "source": [
    "**1. Is the dataset secure if you have achieved k-anonymity?**"
   ]
  },
  {
   "cell_type": "raw",
   "id": "7f275062",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f22e0f77",
   "metadata": {},
   "source": [
    "**2. Think about your past three days, have you encountered any situation where bias implemented by engineering had an effect on you?**"
   ]
  },
  {
   "cell_type": "raw",
   "id": "1b9bce9d",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
